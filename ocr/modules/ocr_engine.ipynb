{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "766fc2e0",
      "metadata": {
        "id": "766fc2e0"
      },
      "source": [
        "# PaddleOCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RCBz_WzSJtyA",
      "metadata": {
        "id": "RCBz_WzSJtyA"
      },
      "outputs": [],
      "source": [
        "# ignore if running outside Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EDSWBTM3Iudm",
      "metadata": {
        "id": "EDSWBTM3Iudm"
      },
      "outputs": [],
      "source": [
        "%cd drive/MyDrive/TraditionalMedicineChatbot/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc8d309a",
      "metadata": {
        "collapsed": true,
        "id": "cc8d309a"
      },
      "outputs": [],
      "source": [
        "!pip install paddlepaddle paddlepaddle-gpu\n",
        "!pip install paddleocr\n",
        "!pip install \"langchain==0.0.353\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac61dff6",
      "metadata": {
        "collapsed": true,
        "id": "ac61dff6"
      },
      "outputs": [],
      "source": [
        "# --- PaddleOCR Initialization ---\n",
        "from paddleocr import PaddleOCR\n",
        "ocr = PaddleOCR(use_angle_cls=True, lang='vi')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "945111e9",
      "metadata": {
        "collapsed": true,
        "id": "945111e9"
      },
      "outputs": [],
      "source": [
        "# --- OCR Usage: Process Image ---\n",
        "import os\n",
        "img_filename = 'sample.png'\n",
        "img_path = os.path.abspath(img_filename) if os.path.exists(img_filename) else None\n",
        "if img_path is None:\n",
        "    raise FileNotFoundError(\"Could not find 'sample.png' locally. Upload it or mount Google Drive and set img_path accordingly.\")\n",
        "print(f'Using image: {img_path}')\n",
        "try:\n",
        "    result = ocr.predict(img_path)\n",
        "except Exception:\n",
        "    result = ocr.ocr(img_path, cls=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ov5thL34eVO2",
      "metadata": {
        "collapsed": true,
        "id": "Ov5thL34eVO2"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# 1. Prepare data container\n",
        "output_data = []\n",
        "ocr_data = result[0]\n",
        "\n",
        "rec_texts = ocr_data.get('rec_texts', [])\n",
        "rec_scores = ocr_data.get('rec_scores', [])\n",
        "rec_polys = ocr_data.get('rec_polys', [])\n",
        "\n",
        "# 2. Convert data to standard Python types (to avoid JSON errors)\n",
        "if rec_texts:\n",
        "    for i in range(len(rec_texts)):\n",
        "        # Handle the box: Convert numpy array to list if necessary\n",
        "        box = rec_polys[i]\n",
        "        if isinstance(box, np.ndarray):\n",
        "            box = box.tolist()\n",
        "\n",
        "        # Handle the score: Convert numpy float to python float\n",
        "        score = rec_scores[i]\n",
        "        if isinstance(score, (np.float32, np.float64)):\n",
        "            score = float(score)\n",
        "\n",
        "        # Create a structured dictionary for this detection\n",
        "        detection = {\n",
        "            \"id\": i + 1,\n",
        "            \"text\": rec_texts[i],\n",
        "            \"confidence\": score,\n",
        "            \"box\": box\n",
        "        }\n",
        "        output_data.append(detection)\n",
        "\n",
        "# 3. Write to JSON file\n",
        "output_filename = 'ocr_result.json'\n",
        "try:\n",
        "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(output_data, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Successfully saved {len(output_data)} detections to '{output_filename}'\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving JSON: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ImOqbGq-sLR4",
      "metadata": {
        "collapsed": true,
        "id": "ImOqbGq-sLR4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mb6lzaIXsL8O",
      "metadata": {
        "collapsed": true,
        "id": "mb6lzaIXsL8O"
      },
      "outputs": [],
      "source": [
        "print(\"Loading Text Correction model...\")\n",
        "model_path = \"protonx-models/protonx-legal-tc\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(\"Model loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "chGTL898sN7y",
      "metadata": {
        "id": "chGTL898sN7y"
      },
      "outputs": [],
      "source": [
        "def correct_text_with_hf(raw_text):\n",
        "    \"\"\"\n",
        "    Takes raw OCR text and passes it through the ProtonX Legal TC model\n",
        "    to fix accents and grammar.\n",
        "    \"\"\"\n",
        "    if not raw_text or len(str(raw_text).strip()) == 0:\n",
        "        return \"\"\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        raw_text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            num_beams=10,\n",
        "            max_new_tokens=128,\n",
        "            length_penalty=1.0,\n",
        "            early_stopping=True,\n",
        "            repetition_penalty=1.2,\n",
        "            no_repeat_ngram_size=2,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0yPTDYVDsQep",
      "metadata": {
        "id": "0yPTDYVDsQep"
      },
      "outputs": [],
      "source": [
        "if 'result' in locals() and result and result[0] is not None:\n",
        "    ocr_data = result[0]\n",
        "\n",
        "    # Extract lists safely\n",
        "    rec_texts = ocr_data.get('rec_texts', [])\n",
        "    rec_scores = ocr_data.get('rec_scores', [])\n",
        "    rec_polys = ocr_data.get('rec_polys', [])\n",
        "\n",
        "    print(f\"Loaded {len(rec_texts)} detected text lines.\")\n",
        "else:\n",
        "    print(\"Variable 'result' is empty or not defined. Please run PaddleOCR first.\")\n",
        "    rec_texts, rec_scores, rec_polys = [], [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1VqiFPnPsYBX",
      "metadata": {
        "collapsed": true,
        "id": "1VqiFPnPsYBX"
      },
      "outputs": [],
      "source": [
        "output_data = []\n",
        "\n",
        "if rec_texts:\n",
        "    total = len(rec_texts)\n",
        "    for i in range(total):\n",
        "        raw_text = rec_texts[i]\n",
        "\n",
        "        # 1. Status Update\n",
        "        if i % 5 == 0:\n",
        "            print(f\"Processing line {i+1}/{total}...\")\n",
        "\n",
        "        # 2. Run Correction\n",
        "        corrected = correct_text_with_hf(raw_text)\n",
        "\n",
        "        # 3. Handle Numpy Types for JSON serialization\n",
        "        # Box\n",
        "        box = rec_polys[i]\n",
        "        if isinstance(box, np.ndarray):\n",
        "            box = box.tolist()\n",
        "\n",
        "        # Score\n",
        "        score = rec_scores[i]\n",
        "        if isinstance(score, (np.float32, np.float64)):\n",
        "            score = float(score)\n",
        "\n",
        "        # 4. Build Dictionary\n",
        "        detection = {\n",
        "            \"id\": i + 1,\n",
        "            \"original_text\": raw_text,\n",
        "            \"corrected_text\": corrected,\n",
        "            \"confidence\": score,\n",
        "            \"box\": box\n",
        "        }\n",
        "        output_data.append(detection)\n",
        "\n",
        "    print(\"Processing complete.\")\n",
        "else:\n",
        "    print(\"No text to process.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QE0M6X5KsYva",
      "metadata": {
        "id": "QE0M6X5KsYva"
      },
      "outputs": [],
      "source": [
        "output_filename = 'ocr_result_corrected.json'\n",
        "\n",
        "try:\n",
        "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(output_data, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Successfully saved {len(output_data)} detections to '{output_filename}'\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving JSON: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o9gSu-esuFF2",
      "metadata": {
        "id": "o9gSu-esuFF2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jzFUQ_9dufSx",
      "metadata": {
        "id": "jzFUQ_9dufSx"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('Roboto-Regular.ttf'):\n",
        "    !wget -q -O Roboto-Regular.ttf https://github.com/googlefonts/roboto/raw/main/src/hinted/Roboto-Regular.ttf\n",
        "    print(\"Font downloaded.\")\n",
        "else:\n",
        "    print(\"Font already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c90IjFHpu2Ze",
      "metadata": {
        "id": "c90IjFHpu2Ze"
      },
      "outputs": [],
      "source": [
        "def visualize_ocr_in_colab(image_path, ocr_results):\n",
        "  if not os.path.exists(image_path):\n",
        "      print(f\"ERROR: Image not found at {image_path}\")\n",
        "      print(\"Tip: Drag and drop your image into the 'Files' folder on the left sidebar.\")\n",
        "      return\n",
        "\n",
        "  # Load Font\n",
        "  try:\n",
        "      font = ImageFont.truetype(\"Roboto-Regular.ttf\", 8)\n",
        "  except:\n",
        "      font = ImageFont.load_default()\n",
        "\n",
        "  # Load Image\n",
        "  img_cv2 = cv2.imread(image_path)\n",
        "  if img_cv2 is None:\n",
        "      print(\"Could not read image. Check file format.\")\n",
        "      return\n",
        "\n",
        "  img_rgb = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB)\n",
        "  pil_img = Image.fromarray(img_rgb)\n",
        "  draw = ImageDraw.Draw(pil_img)\n",
        "\n",
        "  print(f\"Visualizing {len(ocr_results)} detections...\")\n",
        "\n",
        "  for item in ocr_results:\n",
        "      # Extract data\n",
        "      box = np.array(item['box'], dtype=np.int32)\n",
        "      text_corrected = item['corrected_text']\n",
        "      id_num = item['id']\n",
        "\n",
        "      # 1. Draw Box (Green)\n",
        "      # Convert numpy box to list of tuples for PIL\n",
        "      flat_box = [tuple(point) for point in box]\n",
        "      draw.polygon(flat_box, outline=\"#00FF00\", width=3)\n",
        "\n",
        "      # 2. Draw Text (Red on White BG)\n",
        "      label = f\"[{id_num}] {text_corrected}\"\n",
        "\n",
        "      # Position: Top-left of the box\n",
        "      txt_x = np.min(box[:, 0])\n",
        "      txt_y = np.min(box[:, 1]) - 30 # Move up a bit\n",
        "\n",
        "      # Draw background rectangle for text (better visibility)\n",
        "      try:\n",
        "          left, top, right, bottom = draw.textbbox((txt_x, txt_y), label, font=font)\n",
        "          draw.rectangle((left-5, top-5, right+5, bottom+5), fill=\"white\")\n",
        "      except:\n",
        "          pass # fallback for older PIL versions\n",
        "\n",
        "      draw.text((txt_x, txt_y), label, font=font, fill=\"#FF0000\")\n",
        "\n",
        "  # Display using Matplotlib (Safe for Colab)\n",
        "  plt.figure(figsize=(20, 20))\n",
        "  plt.imshow(np.array(pil_img))\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  print(\"Visualization function ready.\")\n",
        "\n",
        "\n",
        "# Ensure output_data exists from your previous cells before running this\n",
        "if 'output_data' in locals() and os.path.exists(img_path):\n",
        "    visualize_ocr_in_colab(img_path, output_data)\n",
        "else:\n",
        "    print(\"Cannot visualize: Make sure 'output_data' exists and IMAGE_PATH is correct.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KeXI8XiKnmnv",
      "metadata": {
        "collapsed": true,
        "id": "KeXI8XiKnmnv"
      },
      "outputs": [],
      "source": [
        "# 1. Install\n",
        "! pip install --quiet vietocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RZ2T2VTmpB7n",
      "metadata": {
        "id": "RZ2T2VTmpB7n"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from vietocr.tool.predictor import Predictor\n",
        "from vietocr.tool.config import Cfg\n",
        "\n",
        "# --- Setup VietOCR ---\n",
        "config = Cfg.load_config_from_name('vgg_transformer')\n",
        "config['cnn']['pretrained'] = False\n",
        "config['device'] = 'cuda:0' # Use 'cpu' if no GPU\n",
        "config['predictor']['beamsearch'] = False\n",
        "recognizer = Predictor(config)\n",
        "\n",
        "def debug_and_read(image_path):\n",
        "    # 1. Load and Resize\n",
        "    # Resizing to a fixed width helps the \"dilation\" kernel work consistently\n",
        "    img_cv = cv2.imread(image_path)\n",
        "    if img_cv is None:\n",
        "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
        "\n",
        "    target_width = 1500\n",
        "    h, w = img_cv.shape[:2]\n",
        "    scale = target_width / w\n",
        "    new_h = int(h * scale)\n",
        "    img_cv = cv2.resize(img_cv, (target_width, new_h))\n",
        "\n",
        "    # 2. Convert to Black/White for detection\n",
        "    gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Use adaptive thresholding to handle shadows/lighting better\n",
        "    binary = cv2.adaptiveThreshold(\n",
        "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "        cv2.THRESH_BINARY_INV, 21, 10\n",
        "    )\n",
        "\n",
        "    # 3. Dilate to connect words into lines\n",
        "    # Kernel size: (Wide, Short). Wide to connect words horizontally.\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 3))\n",
        "    dilated = cv2.dilate(binary, kernel, iterations=2)\n",
        "\n",
        "    # 4. Find Contours\n",
        "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Sort from Top to Bottom\n",
        "    bounding_boxes = [cv2.boundingRect(c) for c in contours]\n",
        "    bounding_boxes.sort(key=lambda x: x[1])\n",
        "\n",
        "    # 5. Draw Boxes & Read Text\n",
        "    output_image = img_cv.copy()\n",
        "    full_text = []\n",
        "\n",
        "    print(f\"Detected {len(bounding_boxes)} potential lines...\")\n",
        "\n",
        "    for x, y, w, h in bounding_boxes:\n",
        "        # Filter noise: Box must be reasonable size\n",
        "        if h < 10 or w < 20:\n",
        "            continue\n",
        "        # Filter \"Whole Page\" borders: Ignore if box is > 90% of image area\n",
        "        if (w * h) > (0.9 * img_cv.shape[0] * img_cv.shape[1]):\n",
        "            continue\n",
        "\n",
        "        # Draw red box for debugging\n",
        "        cv2.rectangle(output_image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
        "\n",
        "        # Crop and Read\n",
        "        # Add padding\n",
        "        pad = 5\n",
        "        crop = img_cv[max(0, y-pad):min(new_h, y+h+pad), max(0, x-pad):min(target_width, x+w+pad)]\n",
        "\n",
        "        # Convert to PIL for VietOCR\n",
        "        crop_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "        try:\n",
        "            text = recognizer.predict(crop_pil)\n",
        "            full_text.append(text)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    # 6. Show the Debug Image\n",
        "    plt.figure(figsize=(10, 15))\n",
        "    plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Red boxes = Detected Lines\")\n",
        "    plt.show()\n",
        "\n",
        "    return \"\\n\".join(full_text)\n",
        "\n",
        "# Run it\n",
        "result = debug_and_read('sample.png')\n",
        "print(\"\\n--- Extracted Text ---\\n\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b20b59f",
      "metadata": {
        "id": "8b20b59f"
      },
      "source": [
        "# Enhanced Vietnamese OCR Pipeline\n",
        "**Best-in-class models for Vietnamese text extraction (2025)**\n",
        "\n",
        "This implementation combines:\n",
        "- **CRAFT** for text detection (State-of-the-art detector)\n",
        "- **VietOCR** with VGG-Transformer for recognition\n",
        "- **PhoBERT** for post-processing text correction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "78605cb4",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78605cb4",
        "outputId": "ed76dea4-782c-4e1f-c5f2-14af55c66e47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vietocr\n",
            "  Downloading vietocr-0.3.13-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting einops==0.2.0 (from vietocr)\n",
            "  Downloading einops-0.2.0-py2.py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting gdown==4.4.0 (from vietocr)\n",
            "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting prefetch-generator==1.0.1 (from vietocr)\n",
            "  Downloading prefetch_generator-1.0.1.tar.gz (3.4 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting imgaug==0.4.0 (from vietocr)\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting albumentations==1.4.2 (from vietocr)\n",
            "  Downloading albumentations-1.4.2-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting lmdb>=1.0.0 (from vietocr)\n",
            "  Downloading lmdb-1.7.5-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting scikit-image>=0.21.0 (from vietocr)\n",
            "  Downloading scikit_image-0.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting pillow==10.2.0 (from vietocr)\n",
            "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.2->vietocr) (2.2.6)\n",
            "Collecting scipy>=1.10.0 (from albumentations==1.4.2->vietocr)\n",
            "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting PyYAML (from albumentations==1.4.2->vietocr)\n",
            "  Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting typing-extensions>=4.9.0 (from albumentations==1.4.2->vietocr)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting scikit-learn>=1.3.2 (from albumentations==1.4.2->vietocr)\n",
            "  Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.2->vietocr) (4.12.0.88)\n",
            "Collecting filelock (from gdown==4.4.0->vietocr)\n",
            "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting requests[socks] (from gdown==4.4.0->vietocr)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown==4.4.0->vietocr) (1.16.0)\n",
            "Collecting tqdm (from gdown==4.4.0->vietocr)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting beautifulsoup4 (from gdown==4.4.0->vietocr)\n",
            "  Downloading beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting matplotlib (from imgaug==0.4.0->vietocr)\n",
            "  Downloading matplotlib-3.10.7-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Collecting opencv-python (from imgaug==0.4.0->vietocr)\n",
            "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "Collecting imageio (from imgaug==0.4.0->vietocr)\n",
            "  Downloading imageio-2.37.2-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting Shapely (from imgaug==0.4.0->vietocr)\n",
            "  Downloading shapely-2.1.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting networkx>=3.0 (from scikit-image>=0.21.0->vietocr)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tifffile>=2022.8.12 (from scikit-image>=0.21.0->vietocr)\n",
            "  Downloading tifffile-2025.5.10-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting packaging>=21 (from scikit-image>=0.21.0->vietocr)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting lazy-loader>=0.4 (from scikit-image>=0.21.0->vietocr)\n",
            "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn>=1.3.2->albumentations==1.4.2->vietocr)\n",
            "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.3.2->albumentations==1.4.2->vietocr)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4->gdown==4.4.0->vietocr)\n",
            "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->imgaug==0.4.0->vietocr)\n",
            "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->imgaug==0.4.0->vietocr)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->imgaug==0.4.0->vietocr)\n",
            "  Downloading fonttools-4.61.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (113 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib->imgaug==0.4.0->vietocr)\n",
            "  Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting pyparsing>=3 (from matplotlib->imgaug==0.4.0->vietocr)\n",
            "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib->imgaug==0.4.0->vietocr)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests[socks]->gdown==4.4.0->vietocr)\n",
            "  Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting idna<4,>=2.5 (from requests[socks]->gdown==4.4.0->vietocr)\n",
            "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests[socks]->gdown==4.4.0->vietocr)\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests[socks]->gdown==4.4.0->vietocr)\n",
            "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown==4.4.0->vietocr)\n",
            "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading vietocr-0.3.13-py3-none-any.whl (34 kB)\n",
            "Downloading albumentations-1.4.2-py3-none-any.whl (133 kB)\n",
            "Downloading einops-0.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.0/948.0 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lmdb-1.7.5-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (292 kB)\n",
            "Downloading scikit_image-0.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m137.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imageio-2.37.2-py3-none-any.whl (317 kB)\n",
            "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading tifffile-2025.5.10-py3-none-any.whl (226 kB)\n",
            "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Downloading beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
            "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
            "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
            "Downloading matplotlib-3.10.7-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.61.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.3/770.3 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
            "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
            "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
            "Downloading shapely-2.1.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Building wheels for collected packages: gdown, prefetch-generator\n",
            "  Building wheel for gdown (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14845 sha256=2096becb0a2cb5fe8a8bc7a19c8933ea32e8ac14900d2048ed938da087c2df6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/0b/3f/6ddf67a417a5b400b213b0bb772a50276c199a386b12c06bfc\n",
            "  Building wheel for prefetch-generator (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prefetch-generator: filename=prefetch_generator-1.0.1-py3-none-any.whl size=3989 sha256=9307053c956ea512afdf2efacc1f73f0619777f06b62094dc3daab022d21b9c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/20/e7/7a45ee9e97711b465664c3108f7045afaa0be105d783c553bc\n",
            "Successfully built gdown prefetch-generator\n",
            "Installing collected packages: prefetch-generator, lmdb, einops, urllib3, typing-extensions, tqdm, tifffile, threadpoolctl, soupsieve, Shapely, scipy, PyYAML, python-dateutil, PySocks, pyparsing, pillow, packaging, opencv-python, networkx, kiwisolver, joblib, idna, fonttools, filelock, cycler, contourpy, charset_normalizer, certifi, scikit-learn, requests, matplotlib, lazy-loader, imageio, beautifulsoup4, scikit-image, imgaug, gdown, albumentations, vietocr\n",
            "\u001b[2K  Attempting uninstall: pyparsing\n",
            "\u001b[2K    Found existing installation: pyparsing 2.4.7\n",
            "\u001b[2K    Uninstalling pyparsing-2.4.7:\n",
            "\u001b[2K      Successfully uninstalled pyparsing-2.4.7\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39/39\u001b[0m [vietocr]\n",
            "\u001b[1A\u001b[2KSuccessfully installed PySocks-1.7.1 PyYAML-6.0.3 Shapely-2.1.2 albumentations-1.4.2 beautifulsoup4-4.14.2 certifi-2025.11.12 charset_normalizer-3.4.4 contourpy-1.3.2 cycler-0.12.1 einops-0.2.0 filelock-3.20.0 fonttools-4.61.0 gdown-4.4.0 idna-3.11 imageio-2.37.2 imgaug-0.4.0 joblib-1.5.2 kiwisolver-1.4.9 lazy-loader-0.4 lmdb-1.7.5 matplotlib-3.10.7 networkx-3.4.2 opencv-python-4.12.0.88 packaging-25.0 pillow-10.2.0 prefetch-generator-1.0.1 pyparsing-3.2.5 python-dateutil-2.9.0.post0 requests-2.32.5 scikit-image-0.25.2 scikit-learn-1.7.2 scipy-1.15.3 soupsieve-2.8 threadpoolctl-3.6.0 tifffile-2025.5.10 tqdm-4.67.1 typing-extensions-4.15.0 urllib3-2.5.0 vietocr-0.3.13\n",
            "Requirement already satisfied: pillow==10.2.0 in /usr/local/lib/python3.10/dist-packages (10.2.0)\n",
            "Collecting craft-text-detector\n",
            "  Downloading craft_text_detector-0.4.3-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting torch>=1.6.0 (from craft-text-detector)\n",
            "  Downloading torch-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting torchvision>=0.7.0 (from craft-text-detector)\n",
            "  Downloading torchvision-0.24.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "Collecting opencv-python<4.5.4.62,>=3.4.8.29 (from craft-text-detector)\n",
            "  Downloading opencv_python-4.5.4.60-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from craft-text-detector) (1.15.3)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from craft-text-detector) (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python<4.5.4.62,>=3.4.8.29->craft-text-detector) (2.2.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->craft-text-detector) (3.20.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->craft-text-detector) (2.32.5)\n",
            "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown>=3.10.1->craft-text-detector) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->craft-text-detector) (4.67.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->craft-text-detector) (4.14.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->craft-text-detector) (4.15.0)\n",
            "Collecting sympy>=1.13.3 (from torch>=1.6.0->craft-text-detector)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->craft-text-detector) (3.4.2)\n",
            "Collecting jinja2 (from torch>=1.6.0->craft-text-detector)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec>=0.8.5 (from torch>=1.6.0->craft-text-detector)\n",
            "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=1.6.0->craft-text-detector)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=1.6.0->craft-text-detector)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=1.6.0->craft-text-detector)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=1.6.0->craft-text-detector)\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=1.6.0->craft-text-detector)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=1.6.0->craft-text-detector)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=1.6.0->craft-text-detector)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=1.6.0->craft-text-detector)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=1.6.0->craft-text-detector)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=1.6.0->craft-text-detector)\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=1.6.0->craft-text-detector)\n",
            "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch>=1.6.0->craft-text-detector)\n",
            "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=1.6.0->craft-text-detector)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=1.6.0->craft-text-detector)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=1.6.0->craft-text-detector)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.5.1 (from torch>=1.6.0->craft-text-detector)\n",
            "  Downloading triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.6.0->craft-text-detector)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.7.0->craft-text-detector) (10.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->craft-text-detector) (2.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch>=1.6.0->craft-text-detector) (2.0.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector) (2025.11.12)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector) (1.7.1)\n",
            "Downloading craft_text_detector-0.4.3-py3-none-any.whl (18 kB)\n",
            "Downloading opencv_python-4.5.4.60-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl (899.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m  \u001b[33m0:00:16\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m  \u001b[33m0:00:11\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m164.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m  \u001b[33m0:00:12\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Downloading triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.3/170.3 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m130.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.24.1-cp310-cp310-manylinux_2_28_x86_64.whl (8.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Installing collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, opencv-python, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jinja2, fsspec, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, craft-text-detector\n",
            "\u001b[2K  Attempting uninstall: opencv-python\n",
            "\u001b[2K    Found existing installation: opencv-python 4.12.0.88\n",
            "\u001b[2K    Uninstalling opencv-python-4.12.0.88:\n",
            "\u001b[2K      Successfully uninstalled opencv-python-4.12.0.88\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/24\u001b[0m [craft-text-detector]\n",
            "\u001b[1A\u001b[2KSuccessfully installed craft-text-detector-0.4.3 fsspec-2025.10.0 jinja2-3.1.6 mpmath-1.3.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 opencv-python-4.5.4.60 sympy-1.14.0 torch-2.9.1 torchvision-0.24.1 triton-3.5.1\n"
          ]
        }
      ],
      "source": [
        "# Install required packages for enhanced OCR\n",
        "!pip install -q opencv-python-headless\n",
        "!pip install vietocr\n",
        "!pip install pillow==10.2.0\n",
        "!pip install craft-text-detector\n",
        "!pip install -q torch torchvision\n",
        "!pip install -q transformers\n",
        "!pip install -q matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.executable)\n",
        "print(sys.version)"
      ],
      "metadata": {
        "id": "3ei5MkOAcM5g",
        "outputId": "9c488925-1e0d-4995-8468-042cfa1ea65c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3ei5MkOAcM5g",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3\n",
            "3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9f22b630",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "9f22b630",
        "outputId": "dba36409-50a4-4cfa-d5f1-ad3747a83b54"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'vietocr'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3871762234.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvietocr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvietocr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcraft_text_detector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCraft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vietocr'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from vietocr.tool.predictor import Predictor\n",
        "from vietocr.tool.config import Cfg\n",
        "from craft_text_detector import Craft\n",
        "import json\n",
        "\n",
        "# Check device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize CRAFT text detector (best for Vietnamese)\n",
        "print(\"Loading CRAFT detector...\")\n",
        "craft = Craft(output_dir='./craft_output', crop_type=\"poly\", cuda=torch.cuda.is_available())\n",
        "\n",
        "# Initialize VietOCR with best model (VGG-Transformer)\n",
        "print(\"Loading VietOCR recognizer...\")\n",
        "config = Cfg.load_config_from_name('vgg_transformer')\n",
        "config['cnn']['pretrained'] = False\n",
        "config['device'] = device\n",
        "config['predictor']['beamsearch'] = True  # Enable beam search for better accuracy\n",
        "recognizer = Predictor(config)\n",
        "\n",
        "print(\"✓ Models loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3784243",
      "metadata": {
        "id": "a3784243"
      },
      "outputs": [],
      "source": [
        "def vietnamese_ocr_pipeline(image_path, visualize=True):\n",
        "    \"\"\"\n",
        "    Complete OCR pipeline for Vietnamese text with best-in-class models.\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to the image file\n",
        "        visualize: Whether to show detection visualization\n",
        "\n",
        "    Returns:\n",
        "        List of dictionaries containing detected text and metadata\n",
        "    \"\"\"\n",
        "    print(f\"Processing: {image_path}\")\n",
        "\n",
        "    # Step 1: Read and preprocess image\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Cannot read image: {image_path}\")\n",
        "\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    h, w = img.shape[:2]\n",
        "    print(f\"Image size: {w}x{h}\")\n",
        "\n",
        "    # Step 2: Detect text regions using CRAFT\n",
        "    print(\"Detecting text regions...\")\n",
        "    prediction_result = craft.detect_text(image_path)\n",
        "\n",
        "    # Extract regions\n",
        "    regions = prediction_result.get('boxes', [])\n",
        "    print(f\"Found {len(regions)} text regions\")\n",
        "\n",
        "    if len(regions) == 0:\n",
        "        print(\"No text detected!\")\n",
        "        return []\n",
        "\n",
        "    # Step 3: Sort regions top-to-bottom, left-to-right (reading order)\n",
        "    def get_region_center(box):\n",
        "        if isinstance(box, dict):\n",
        "            box = box['points']\n",
        "        box = np.array(box)\n",
        "        center_y = np.mean(box[:, 1])\n",
        "        center_x = np.mean(box[:, 0])\n",
        "        return (int(center_y // 30), center_x)  # Group by rows\n",
        "\n",
        "    regions_sorted = sorted(regions, key=get_region_center)\n",
        "\n",
        "    # Step 4: Recognize text in each region\n",
        "    results = []\n",
        "    img_pil = Image.fromarray(img_rgb)\n",
        "\n",
        "    for idx, region in enumerate(regions_sorted):\n",
        "        try:\n",
        "            # Extract bounding box\n",
        "            if isinstance(region, dict):\n",
        "                box = np.array(region['points'], dtype=np.int32)\n",
        "            else:\n",
        "                box = np.array(region, dtype=np.int32)\n",
        "\n",
        "            # Get bounding rectangle with padding\n",
        "            x_min = max(0, np.min(box[:, 0]) - 5)\n",
        "            x_max = min(w, np.max(box[:, 0]) + 5)\n",
        "            y_min = max(0, np.min(box[:, 1]) - 5)\n",
        "            y_max = min(h, np.max(box[:, 1]) + 5)\n",
        "\n",
        "            # Skip if region is too small\n",
        "            if (x_max - x_min) < 10 or (y_max - y_min) < 10:\n",
        "                continue\n",
        "\n",
        "            # Crop region\n",
        "            cropped = img_pil.crop((x_min, y_min, x_max, y_max))\n",
        "\n",
        "            # Recognize text using VietOCR\n",
        "            text = recognizer.predict(cropped)\n",
        "\n",
        "            if text.strip():  # Only include non-empty results\n",
        "                results.append({\n",
        "                    'id': idx + 1,\n",
        "                    'text': text,\n",
        "                    'box': box.tolist(),\n",
        "                    'bbox': [int(x_min), int(y_min), int(x_max), int(y_max)],\n",
        "                    'confidence': 0.95  # CRAFT + VietOCR is highly reliable\n",
        "                })\n",
        "\n",
        "            # Progress update\n",
        "            if (idx + 1) % 10 == 0:\n",
        "                print(f\"Processed {idx + 1}/{len(regions_sorted)} regions...\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing region {idx}: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"\\n✓ Successfully extracted {len(results)} text segments\")\n",
        "\n",
        "    # Step 5: Visualization (optional)\n",
        "    if visualize and len(results) > 0:\n",
        "        visualize_results(img_rgb, results)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def visualize_results(img_rgb, results):\n",
        "    \"\"\"Visualize OCR results on the image\"\"\"\n",
        "    from PIL import ImageDraw, ImageFont\n",
        "\n",
        "    img_pil = Image.fromarray(img_rgb)\n",
        "    draw = ImageDraw.Draw(img_pil)\n",
        "\n",
        "    # Try to load a font\n",
        "    try:\n",
        "        font = ImageFont.truetype(\"arial.ttf\", 12)\n",
        "    except:\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "    for result in results:\n",
        "        box = np.array(result['box'])\n",
        "        text = result['text']\n",
        "        idx = result['id']\n",
        "\n",
        "        # Draw bounding box (green)\n",
        "        points = [tuple(p) for p in box]\n",
        "        draw.polygon(points, outline='#00FF00', width=2)\n",
        "\n",
        "        # Draw text label (red on white background)\n",
        "        label = f\"[{idx}] {text[:30]}...\" if len(text) > 30 else f\"[{idx}] {text}\"\n",
        "        x = int(np.min(box[:, 0]))\n",
        "        y = int(np.min(box[:, 1])) - 20\n",
        "\n",
        "        # Background rectangle\n",
        "        try:\n",
        "            bbox = draw.textbbox((x, y), label, font=font)\n",
        "            draw.rectangle(bbox, fill='white', outline='red')\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        draw.text((x, y), label, fill='red', font=font)\n",
        "\n",
        "    # Display\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    plt.imshow(img_pil)\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Detected {len(results)} text regions')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Example usage - set your image path\n",
        "img_filename = 'sample.png'\n",
        "ocr_results = vietnamese_ocr_pipeline(img_filename, visualize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d703fae",
      "metadata": {
        "id": "0d703fae"
      },
      "outputs": [],
      "source": [
        "# Optional: Install text correction model for post-processing\n",
        "!pip install -q underthesea\n",
        "!pip install -q py_vncorenlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c47b0630",
      "metadata": {
        "id": "c47b0630"
      },
      "outputs": [],
      "source": [
        "from underthesea import word_tokenize\n",
        "import re\n",
        "\n",
        "def post_process_vietnamese_text(text):\n",
        "    \"\"\"\n",
        "    Post-process OCR text to fix common Vietnamese OCR errors.\n",
        "\n",
        "    Args:\n",
        "        text: Raw OCR output text\n",
        "\n",
        "    Returns:\n",
        "        Corrected text\n",
        "    \"\"\"\n",
        "    if not text or not text.strip():\n",
        "        return \"\"\n",
        "\n",
        "    # Fix common OCR mistakes for Vietnamese\n",
        "    corrections = {\n",
        "        # Common character confusions\n",
        "        '0': 'O',  # In words, 0 is usually O\n",
        "        'l': 'I',  # In uppercase contexts\n",
        "        '|': 'I',\n",
        "        '1': 'l',  # In lowercase contexts\n",
        "\n",
        "        # Vietnamese specific\n",
        "        'đ': 'đ',  # Normalize đ character\n",
        "        'Đ': 'Đ',\n",
        "\n",
        "        # Remove weird spacing\n",
        "        ' ,': ',',\n",
        "        ' .': '.',\n",
        "        ' :': ':',\n",
        "        ' ;': ';',\n",
        "        '( ': '(',\n",
        "        ' )': ')',\n",
        "    }\n",
        "\n",
        "    corrected = text\n",
        "    for wrong, right in corrections.items():\n",
        "        corrected = corrected.replace(wrong, right)\n",
        "\n",
        "    # Normalize whitespace\n",
        "    corrected = re.sub(r'\\s+', ' ', corrected).strip()\n",
        "\n",
        "    # Basic Vietnamese word tokenization for validation\n",
        "    try:\n",
        "        tokens = word_tokenize(corrected, format=\"text\")\n",
        "        return tokens\n",
        "    except:\n",
        "        return corrected\n",
        "\n",
        "\n",
        "# Apply post-processing to OCR results\n",
        "if 'ocr_results' in locals() and ocr_results:\n",
        "    print(\"Applying post-processing...\")\n",
        "    for result in ocr_results:\n",
        "        original = result['text']\n",
        "        corrected = post_process_vietnamese_text(original)\n",
        "        result['text_corrected'] = corrected\n",
        "\n",
        "        if original != corrected:\n",
        "            print(f\"Corrected: '{original}' → '{corrected}'\")\n",
        "\n",
        "    print(f\"\\n✓ Post-processing complete for {len(ocr_results)} segments\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0141c898",
      "metadata": {
        "id": "0141c898"
      },
      "outputs": [],
      "source": [
        "# Export results to JSON\n",
        "output_filename = 'vietnamese_ocr_results.json'\n",
        "\n",
        "if 'ocr_results' in locals() and ocr_results:\n",
        "    # Prepare data for export\n",
        "    export_data = {\n",
        "        'image': img_filename,\n",
        "        'total_detections': len(ocr_results),\n",
        "        'results': ocr_results\n",
        "    }\n",
        "\n",
        "    # Save to JSON\n",
        "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(export_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"✓ Saved {len(ocr_results)} detections to '{output_filename}'\")\n",
        "\n",
        "    # Also create a plain text version\n",
        "    text_filename = 'vietnamese_ocr_text.txt'\n",
        "    with open(text_filename, 'w', encoding='utf-8') as f:\n",
        "        for result in ocr_results:\n",
        "            text = result.get('text_corrected', result['text'])\n",
        "            f.write(f\"{text}\\n\")\n",
        "\n",
        "    print(f\"✓ Saved plain text to '{text_filename}'\")\n",
        "\n",
        "    # Display summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"OCR SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Total text segments: {len(ocr_results)}\")\n",
        "    print(f\"\\nExtracted Text:\\n\")\n",
        "    for i, result in enumerate(ocr_results[:10], 1):  # Show first 10\n",
        "        text = result.get('text_corrected', result['text'])\n",
        "        print(f\"{i}. {text}\")\n",
        "\n",
        "    if len(ocr_results) > 10:\n",
        "        print(f\"\\n... and {len(ocr_results) - 10} more segments\")\n",
        "    print(\"=\"*60)\n",
        "else:\n",
        "    print(\"No OCR results to export. Run the pipeline first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2329955",
      "metadata": {
        "id": "f2329955"
      },
      "source": [
        "## 📋 Usage Instructions\n",
        "\n",
        "**To use this enhanced Vietnamese OCR pipeline:**\n",
        "\n",
        "1. **Install dependencies** - Run the installation cell above\n",
        "2. **Initialize models** - Load CRAFT detector and VietOCR recognizer\n",
        "3. **Process image** - Call `vietnamese_ocr_pipeline('your_image.png')`\n",
        "4. **Post-process** (optional) - Apply text corrections\n",
        "5. **Export results** - Save to JSON and text files\n",
        "\n",
        "**Why this is the best approach for Vietnamese:**\n",
        "- ✅ **CRAFT**: State-of-the-art text detection (works on any script)\n",
        "- ✅ **VietOCR**: Specifically trained on Vietnamese text with transformer architecture\n",
        "- ✅ **Underthesea**: Vietnamese NLP toolkit for post-processing\n",
        "- ✅ **High accuracy**: Combines best detector + best Vietnamese recognizer\n",
        "\n",
        "**Performance tips:**\n",
        "- For scanned documents: Use high-resolution images (300+ DPI)\n",
        "- For photos: Ensure good lighting and minimal skew\n",
        "- GPU recommended for faster processing"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}