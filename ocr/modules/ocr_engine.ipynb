{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "766fc2e0",
      "metadata": {
        "id": "766fc2e0"
      },
      "source": [
        "# PaddleOCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RCBz_WzSJtyA",
      "metadata": {
        "id": "RCBz_WzSJtyA"
      },
      "outputs": [],
      "source": [
        "# ignore if running outside Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/TraditionalMedicineChatbot/"
      ],
      "metadata": {
        "id": "EDSWBTM3Iudm"
      },
      "id": "EDSWBTM3Iudm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc8d309a",
      "metadata": {
        "collapsed": true,
        "id": "cc8d309a"
      },
      "outputs": [],
      "source": [
        "!pip install paddlepaddle paddlepaddle-gpu\n",
        "!pip install paddleocr\n",
        "!pip install \"langchain==0.0.353\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac61dff6",
      "metadata": {
        "id": "ac61dff6",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# --- PaddleOCR Initialization ---\n",
        "from paddleocr import PaddleOCR\n",
        "ocr = PaddleOCR(use_angle_cls=True, lang='vi')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "945111e9",
      "metadata": {
        "collapsed": true,
        "id": "945111e9"
      },
      "outputs": [],
      "source": [
        "# --- OCR Usage: Process Image ---\n",
        "import os\n",
        "img_filename = 'sample.png'\n",
        "img_path = os.path.abspath(img_filename) if os.path.exists(img_filename) else None\n",
        "if img_path is None:\n",
        "    raise FileNotFoundError(\"Could not find 'sample.png' locally. Upload it or mount Google Drive and set img_path accordingly.\")\n",
        "print(f'Using image: {img_path}')\n",
        "try:\n",
        "    result = ocr.predict(img_path)\n",
        "except Exception:\n",
        "    result = ocr.ocr(img_path, cls=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ov5thL34eVO2",
      "metadata": {
        "id": "Ov5thL34eVO2",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# 1. Prepare data container\n",
        "output_data = []\n",
        "ocr_data = result[0]\n",
        "\n",
        "rec_texts = ocr_data.get('rec_texts', [])\n",
        "rec_scores = ocr_data.get('rec_scores', [])\n",
        "rec_polys = ocr_data.get('rec_polys', [])\n",
        "\n",
        "# 2. Convert data to standard Python types (to avoid JSON errors)\n",
        "if rec_texts:\n",
        "    for i in range(len(rec_texts)):\n",
        "        # Handle the box: Convert numpy array to list if necessary\n",
        "        box = rec_polys[i]\n",
        "        if isinstance(box, np.ndarray):\n",
        "            box = box.tolist()\n",
        "\n",
        "        # Handle the score: Convert numpy float to python float\n",
        "        score = rec_scores[i]\n",
        "        if isinstance(score, (np.float32, np.float64)):\n",
        "            score = float(score)\n",
        "\n",
        "        # Create a structured dictionary for this detection\n",
        "        detection = {\n",
        "            \"id\": i + 1,\n",
        "            \"text\": rec_texts[i],\n",
        "            \"confidence\": score,\n",
        "            \"box\": box\n",
        "        }\n",
        "        output_data.append(detection)\n",
        "\n",
        "# 3. Write to JSON file\n",
        "output_filename = 'ocr_result.json'\n",
        "try:\n",
        "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(output_data, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Successfully saved {len(output_data)} detections to '{output_filename}'\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving JSON: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ImOqbGq-sLR4"
      },
      "id": "ImOqbGq-sLR4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading Text Correction model...\")\n",
        "model_path = \"protonx-models/protonx-legal-tc\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(\"Model loaded successfully.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mb6lzaIXsL8O"
      },
      "id": "mb6lzaIXsL8O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_text_with_hf(raw_text):\n",
        "    \"\"\"\n",
        "    Takes raw OCR text and passes it through the ProtonX Legal TC model\n",
        "    to fix accents and grammar.\n",
        "    \"\"\"\n",
        "    if not raw_text or len(str(raw_text).strip()) == 0:\n",
        "        return \"\"\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        raw_text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            num_beams=10,\n",
        "            max_new_tokens=128,\n",
        "            length_penalty=1.0,\n",
        "            early_stopping=True,\n",
        "            repetition_penalty=1.2,\n",
        "            no_repeat_ngram_size=2,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "chGTL898sN7y"
      },
      "id": "chGTL898sN7y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'result' in locals() and result and result[0] is not None:\n",
        "    ocr_data = result[0]\n",
        "\n",
        "    # Extract lists safely\n",
        "    rec_texts = ocr_data.get('rec_texts', [])\n",
        "    rec_scores = ocr_data.get('rec_scores', [])\n",
        "    rec_polys = ocr_data.get('rec_polys', [])\n",
        "\n",
        "    print(f\"Loaded {len(rec_texts)} detected text lines.\")\n",
        "else:\n",
        "    print(\"Variable 'result' is empty or not defined. Please run PaddleOCR first.\")\n",
        "    rec_texts, rec_scores, rec_polys = [], [], []"
      ],
      "metadata": {
        "id": "0yPTDYVDsQep"
      },
      "id": "0yPTDYVDsQep",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_data = []\n",
        "\n",
        "if rec_texts:\n",
        "    total = len(rec_texts)\n",
        "    for i in range(total):\n",
        "        raw_text = rec_texts[i]\n",
        "\n",
        "        # 1. Status Update\n",
        "        if i % 5 == 0:\n",
        "            print(f\"Processing line {i+1}/{total}...\")\n",
        "\n",
        "        # 2. Run Correction\n",
        "        corrected = correct_text_with_hf(raw_text)\n",
        "\n",
        "        # 3. Handle Numpy Types for JSON serialization\n",
        "        # Box\n",
        "        box = rec_polys[i]\n",
        "        if isinstance(box, np.ndarray):\n",
        "            box = box.tolist()\n",
        "\n",
        "        # Score\n",
        "        score = rec_scores[i]\n",
        "        if isinstance(score, (np.float32, np.float64)):\n",
        "            score = float(score)\n",
        "\n",
        "        # 4. Build Dictionary\n",
        "        detection = {\n",
        "            \"id\": i + 1,\n",
        "            \"original_text\": raw_text,\n",
        "            \"corrected_text\": corrected,\n",
        "            \"confidence\": score,\n",
        "            \"box\": box\n",
        "        }\n",
        "        output_data.append(detection)\n",
        "\n",
        "    print(\"Processing complete.\")\n",
        "else:\n",
        "    print(\"No text to process.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1VqiFPnPsYBX"
      },
      "id": "1VqiFPnPsYBX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_filename = 'ocr_result_corrected.json'\n",
        "\n",
        "try:\n",
        "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(output_data, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Successfully saved {len(output_data)} detections to '{output_filename}'\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving JSON: {e}\")"
      ],
      "metadata": {
        "id": "QE0M6X5KsYva"
      },
      "id": "QE0M6X5KsYva",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont"
      ],
      "metadata": {
        "id": "o9gSu-esuFF2"
      },
      "id": "o9gSu-esuFF2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('Roboto-Regular.ttf'):\n",
        "    !wget -q -O Roboto-Regular.ttf https://github.com/googlefonts/roboto/raw/main/src/hinted/Roboto-Regular.ttf\n",
        "    print(\"Font downloaded.\")\n",
        "else:\n",
        "    print(\"Font already exists.\")"
      ],
      "metadata": {
        "id": "jzFUQ_9dufSx"
      },
      "id": "jzFUQ_9dufSx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_ocr_in_colab(image_path, ocr_results):\n",
        "  if not os.path.exists(image_path):\n",
        "      print(f\"ERROR: Image not found at {image_path}\")\n",
        "      print(\"Tip: Drag and drop your image into the 'Files' folder on the left sidebar.\")\n",
        "      return\n",
        "\n",
        "  # Load Font\n",
        "  try:\n",
        "      font = ImageFont.truetype(\"Roboto-Regular.ttf\", 8)\n",
        "  except:\n",
        "      font = ImageFont.load_default()\n",
        "\n",
        "  # Load Image\n",
        "  img_cv2 = cv2.imread(image_path)\n",
        "  if img_cv2 is None:\n",
        "      print(\"Could not read image. Check file format.\")\n",
        "      return\n",
        "\n",
        "  img_rgb = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB)\n",
        "  pil_img = Image.fromarray(img_rgb)\n",
        "  draw = ImageDraw.Draw(pil_img)\n",
        "\n",
        "  print(f\"Visualizing {len(ocr_results)} detections...\")\n",
        "\n",
        "  for item in ocr_results:\n",
        "      # Extract data\n",
        "      box = np.array(item['box'], dtype=np.int32)\n",
        "      text_corrected = item['corrected_text']\n",
        "      id_num = item['id']\n",
        "\n",
        "      # 1. Draw Box (Green)\n",
        "      # Convert numpy box to list of tuples for PIL\n",
        "      flat_box = [tuple(point) for point in box]\n",
        "      draw.polygon(flat_box, outline=\"#00FF00\", width=3)\n",
        "\n",
        "      # 2. Draw Text (Red on White BG)\n",
        "      label = f\"[{id_num}] {text_corrected}\"\n",
        "\n",
        "      # Position: Top-left of the box\n",
        "      txt_x = np.min(box[:, 0])\n",
        "      txt_y = np.min(box[:, 1]) - 30 # Move up a bit\n",
        "\n",
        "      # Draw background rectangle for text (better visibility)\n",
        "      try:\n",
        "          left, top, right, bottom = draw.textbbox((txt_x, txt_y), label, font=font)\n",
        "          draw.rectangle((left-5, top-5, right+5, bottom+5), fill=\"white\")\n",
        "      except:\n",
        "          pass # fallback for older PIL versions\n",
        "\n",
        "      draw.text((txt_x, txt_y), label, font=font, fill=\"#FF0000\")\n",
        "\n",
        "  # Display using Matplotlib (Safe for Colab)\n",
        "  plt.figure(figsize=(20, 20))\n",
        "  plt.imshow(np.array(pil_img))\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  print(\"Visualization function ready.\")\n",
        "\n",
        "\n",
        "# Ensure output_data exists from your previous cells before running this\n",
        "if 'output_data' in locals() and os.path.exists(img_path):\n",
        "    visualize_ocr_in_colab(img_path, output_data)\n",
        "else:\n",
        "    print(\"Cannot visualize: Make sure 'output_data' exists and IMAGE_PATH is correct.\")"
      ],
      "metadata": {
        "id": "c90IjFHpu2Ze"
      },
      "id": "c90IjFHpu2Ze",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Install\n",
        "! pip install --quiet vietocr"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KeXI8XiKnmnv"
      },
      "id": "KeXI8XiKnmnv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from vietocr.tool.predictor import Predictor\n",
        "from vietocr.tool.config import Cfg\n",
        "\n",
        "# --- Setup VietOCR ---\n",
        "config = Cfg.load_config_from_name('vgg_transformer')\n",
        "config['cnn']['pretrained'] = False\n",
        "config['device'] = 'cuda:0' # Use 'cpu' if no GPU\n",
        "config['predictor']['beamsearch'] = False\n",
        "recognizer = Predictor(config)\n",
        "\n",
        "def debug_and_read(image_path):\n",
        "    # 1. Load and Resize\n",
        "    # Resizing to a fixed width helps the \"dilation\" kernel work consistently\n",
        "    img_cv = cv2.imread(image_path)\n",
        "    if img_cv is None:\n",
        "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
        "\n",
        "    target_width = 1500\n",
        "    h, w = img_cv.shape[:2]\n",
        "    scale = target_width / w\n",
        "    new_h = int(h * scale)\n",
        "    img_cv = cv2.resize(img_cv, (target_width, new_h))\n",
        "\n",
        "    # 2. Convert to Black/White for detection\n",
        "    gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Use adaptive thresholding to handle shadows/lighting better\n",
        "    binary = cv2.adaptiveThreshold(\n",
        "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "        cv2.THRESH_BINARY_INV, 21, 10\n",
        "    )\n",
        "\n",
        "    # 3. Dilate to connect words into lines\n",
        "    # Kernel size: (Wide, Short). Wide to connect words horizontally.\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 3))\n",
        "    dilated = cv2.dilate(binary, kernel, iterations=2)\n",
        "\n",
        "    # 4. Find Contours\n",
        "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Sort from Top to Bottom\n",
        "    bounding_boxes = [cv2.boundingRect(c) for c in contours]\n",
        "    bounding_boxes.sort(key=lambda x: x[1])\n",
        "\n",
        "    # 5. Draw Boxes & Read Text\n",
        "    output_image = img_cv.copy()\n",
        "    full_text = []\n",
        "\n",
        "    print(f\"Detected {len(bounding_boxes)} potential lines...\")\n",
        "\n",
        "    for x, y, w, h in bounding_boxes:\n",
        "        # Filter noise: Box must be reasonable size\n",
        "        if h < 10 or w < 20:\n",
        "            continue\n",
        "        # Filter \"Whole Page\" borders: Ignore if box is > 90% of image area\n",
        "        if (w * h) > (0.9 * img_cv.shape[0] * img_cv.shape[1]):\n",
        "            continue\n",
        "\n",
        "        # Draw red box for debugging\n",
        "        cv2.rectangle(output_image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
        "\n",
        "        # Crop and Read\n",
        "        # Add padding\n",
        "        pad = 5\n",
        "        crop = img_cv[max(0, y-pad):min(new_h, y+h+pad), max(0, x-pad):min(target_width, x+w+pad)]\n",
        "\n",
        "        # Convert to PIL for VietOCR\n",
        "        crop_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "        try:\n",
        "            text = recognizer.predict(crop_pil)\n",
        "            full_text.append(text)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    # 6. Show the Debug Image\n",
        "    plt.figure(figsize=(10, 15))\n",
        "    plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Red boxes = Detected Lines\")\n",
        "    plt.show()\n",
        "\n",
        "    return \"\\n\".join(full_text)\n",
        "\n",
        "# Run it\n",
        "result = debug_and_read('sample.png')\n",
        "print(\"\\n--- Extracted Text ---\\n\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "RZ2T2VTmpB7n"
      },
      "id": "RZ2T2VTmpB7n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}