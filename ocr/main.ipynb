{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2ad0981",
   "metadata": {},
   "source": [
    "## 1. Setup Environment\n",
    "\n",
    "Install required dependencies (run once per session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebd71c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running on Google Colab\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running locally\")\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  CUDA version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"No GPU detected - will use CPU (slower)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q paddleocr opencv-python pdf2docx python-docx PyMuPDF\n",
    "!pip install -q numpy==1.26.4 Pillow torch transformers vietocr\n",
    "!pip install -q craft-text-detector matplotlib opencv-contrib-python torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d463e84",
   "metadata": {},
   "source": [
    "## 2. Clone Repository (Colab only)\n",
    "\n",
    "If running on Colab, clone the repository to access the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdefdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    # Clone repository\n",
    "    !git clone https://github.com/HuyTran28/23CLCT2_TraditionalMedicineChatbot.git\n",
    "    \n",
    "    # Change to OCR directory\n",
    "    import os\n",
    "    os.chdir('/content/23CLCT2_TraditionalMedicineChatbot/ocr')\n",
    "    print(\"Repository cloned and working directory set\")\n",
    "else:\n",
    "    print(\"Skipping - not on Colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fe56e2",
   "metadata": {},
   "source": [
    "## 3. Upload Input Files (Colab only)\n",
    "\n",
    "Upload your PDF files to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cef4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Create input directory\n",
    "    Path('./input').mkdir(exist_ok=True)\n",
    "    \n",
    "    print(\"Upload your PDF files:\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # Move uploaded files to input directory\n",
    "    for filename in uploaded.keys():\n",
    "        import shutil\n",
    "        shutil.move(filename, f'./input/{filename}')\n",
    "    \n",
    "    print(f\"\\nUploaded {len(uploaded)} file(s) to ./input/\")\n",
    "else:\n",
    "    print(\"Skipping - not on Colab\")\n",
    "    print(\"   Place your PDF files in the 'input' folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dce5e48",
   "metadata": {},
   "source": [
    "## 4. Initialize Pipeline\n",
    "\n",
    "Set up the OCR pipeline with your preferred settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36183cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Add modules to path\n",
    "sys.path.insert(0, './modules')\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "from modules.pipeline import OCRPipeline\n",
    "\n",
    "print(\"Modules imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaf1109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'input_dir': './input',           # Input folder containing PDFs\n",
    "    'output_dir': './output',         # Output folder for Word files\n",
    "    'temp_dir': './temp',             # Temporary files directory\n",
    "    'dpi': 300,                       # Resolution for image conversion\n",
    "    'enable_preprocessing': True,     # Enable image enhancement\n",
    "    'auto_detect': True,              # Auto-detect digital vs scanned\n",
    "}\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = OCRPipeline(\n",
    "    output_dir=CONFIG['output_dir'],\n",
    "    temp_dir=CONFIG['temp_dir'],\n",
    "    dpi=CONFIG['dpi'],\n",
    "    enable_preprocessing=CONFIG['enable_preprocessing'],\n",
    "    auto_detect=CONFIG['auto_detect']\n",
    ")\n",
    "\n",
    "print(\"Pipeline initialized with configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cc5a97",
   "metadata": {},
   "source": [
    "## 5. Process Single File\n",
    "\n",
    "Process a single PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246871e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the PDF file to process\n",
    "pdf_file = \"sample.pdf\"  # Change this to your filename\n",
    "\n",
    "input_path = Path(CONFIG['input_dir']) / pdf_file\n",
    "\n",
    "if not input_path.exists():\n",
    "    print(f\"File not found: {input_path}\")\n",
    "    print(f\"\\nAvailable files in {CONFIG['input_dir']}:\")\n",
    "    for f in Path(CONFIG['input_dir']).glob('*.pdf'):\n",
    "        print(f\"  - {f.name}\")\n",
    "else:\n",
    "    print(f\"Processing: {pdf_file}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        output_path = pipeline.process_pdf(input_path, mode=None)\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"Success! Output saved to: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9998dc",
   "metadata": {},
   "source": [
    "## 6. Batch Process All Files\n",
    "\n",
    "Process all PDF files in the input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c08db13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Batch processing PDFs from: {CONFIG['input_dir']}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    results = pipeline.process_batch(\n",
    "        input_dir=CONFIG['input_dir'],\n",
    "        pattern=\"*.pdf\",\n",
    "        mode=None  # Auto-detect mode\n",
    "    )\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PROCESSING SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    success_count = 0\n",
    "    for r in results:\n",
    "        status_icon = \"✓\" if r[\"status\"] == \"success\" else \"✗\"\n",
    "        print(f\"{status_icon} {Path(r['input']).name}\")\n",
    "        \n",
    "        if r[\"status\"] == \"success\":\n",
    "            print(f\"   → {r['output']}\")\n",
    "            success_count += 1\n",
    "        else:\n",
    "            print(f\"   Error: {r.get('error', 'Unknown error')}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Completed: {success_count}/{len(results)} files processed successfully\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nBatch processing error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6af5bfc",
   "metadata": {},
   "source": [
    "## 7. Download Results (Colab only)\n",
    "\n",
    "Download the converted Word files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2692315",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    import zipfile\n",
    "    from pathlib import Path\n",
    "    \n",
    "    output_dir = Path(CONFIG['output_dir'])\n",
    "    docx_files = list(output_dir.glob('*.docx'))\n",
    "    \n",
    "    if not docx_files:\n",
    "        print(\"No output files found\")\n",
    "    elif len(docx_files) == 1:\n",
    "        # Download single file\n",
    "        print(f\"Downloading: {docx_files[0].name}\")\n",
    "        files.download(str(docx_files[0]))\n",
    "    else:\n",
    "        # Zip and download multiple files\n",
    "        zip_path = 'ocr_results.zip'\n",
    "        with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "            for docx_file in docx_files:\n",
    "                zipf.write(docx_file, docx_file.name)\n",
    "        \n",
    "        print(f\"Downloading {len(docx_files)} files as {zip_path}\")\n",
    "        files.download(zip_path)\n",
    "else:\n",
    "    print(\"Skipping - not on Colab\")\n",
    "    print(f\"   Output files are in: {CONFIG['output_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d481f08",
   "metadata": {},
   "source": [
    "## 8. Cleanup (Optional)\n",
    "\n",
    "Remove temporary files to free up space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adfbc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "temp_dir = Path(CONFIG['temp_dir'])\n",
    "if temp_dir.exists():\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(f\"Cleaned up temporary files in {temp_dir}\")\n",
    "else:\n",
    "    print(\"No temporary files to clean\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
